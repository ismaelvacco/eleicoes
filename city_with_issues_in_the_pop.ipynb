{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPp9as+/daNJb6ogjlktwzY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ismaelvacco/eleicoes/blob/main/city_with_issues_in_the_pop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLYS6eVDpNhM",
        "outputId": "4954d7ec-b4ce-4c0f-9b40-19c660ae907b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.3.0.tar.gz (281.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.3 MB 47 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.5\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[K     |████████████████████████████████| 199 kB 51.2 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.0-py2.py3-none-any.whl size=281764026 sha256=6f2feb91e31fc2fba8e414ce8531f34cc7fa40e241a7a38151f38459663dceff\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/8e/1b/f73a52650d2e5f337708d9f6a1750d451a7349a867f928b885\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.window import Window\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string\n",
        "import seaborn as sns\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from google.colab import drive\n"
      ],
      "metadata": {
        "id": "n7m3ojXspmOo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tratamento dos dados para unir com o source de municipios"
      ],
      "metadata": {
        "id": "OB25Rxt53x_m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.appName(\"VotosEUrnas\").getOrCreate()\n",
        "\n",
        "pd.options.display.html.table_schema=True\n",
        "path = \"/content/drive\"\n",
        "drive.mount(path)\n",
        "votacao = spark.read.parquet(path + \"/MyDrive/vc\")\n",
        "\n",
        "accent_replacements_spanish = [\n",
        "    (u'á', 'a'), (u'Á', 'A'),\n",
        "    (u'â', 'a'), (u'Â', 'A'),\n",
        "    (u'ã', 'a'), (u'Ã', 'A'),\n",
        "    (u'é', 'e'), (u'É', 'E'),\n",
        "    (u'ê', 'e'), (u'Ê', 'E'),\n",
        "    (u'í', 'i'), (u'Í', 'I'),\n",
        "    (u'ò', 'o'), (u'Ó', 'O'),\n",
        "    (u'ô', 'o'), (u'Ô', 'O'),\n",
        "    (u'õ', 'o'), (u'Õ', 'O'),\n",
        "    (u'ú|ü', 'u'), (u'Ú|Ű', 'U'),\n",
        "    (u'ñ', 'n'),\n",
        "    (u'ç', 'c'), (u'Ç', 'C'),\n",
        "    # see http://stackoverflow.com/a/18123985/3810493 for other characters\n",
        "\n",
        "    # this will convert other non ASCII characters to a question mark:\n",
        "    ('[^\\x00-\\x7F]', '?') \n",
        "]\n",
        "\n",
        "def remove_accents(column):\n",
        "    r = col(column)\n",
        "    for a, b in accent_replacements_spanish:\n",
        "        r = regexp_replace(r, a, b)\n",
        "    return r\n",
        "\n",
        "votacao = votacao.withColumn('city_no_accents', remove_accents('cidade'))\n",
        "votacao.createOrReplaceTempView(\"vc\")\n",
        "\n",
        "municipios = spark.read.csv(path + \"/MyDrive/municipios\", header=True)\n",
        "municipios.createOrReplaceTempView(\"municipios\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J0w4z4foqIvV",
        "outputId": "f273549a-f566-4c61-99bb-510346b55dca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "votacao.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qky1iJPPr1wS",
        "outputId": "0f3a3552-e0f8-49c8-e4bf-86ff00c5112e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- bolsonaro: integer (nullable = true)\n",
            " |-- lula: integer (nullable = true)\n",
            " |-- tebet: integer (nullable = true)\n",
            " |-- ciro: integer (nullable = true)\n",
            " |-- soraya: integer (nullable = true)\n",
            " |-- davila: integer (nullable = true)\n",
            " |-- kelmon: integer (nullable = true)\n",
            " |-- pericles: integer (nullable = true)\n",
            " |-- sofia: integer (nullable = true)\n",
            " |-- vera: integer (nullable = true)\n",
            " |-- eymael: integer (nullable = true)\n",
            " |-- brancos: integer (nullable = true)\n",
            " |-- nulos: integer (nullable = true)\n",
            " |-- cidade: string (nullable = true)\n",
            " |-- uf: string (nullable = true)\n",
            " |-- zona: integer (nullable = true)\n",
            " |-- secao: integer (nullable = true)\n",
            " |-- local_votacao: integer (nullable = true)\n",
            " |-- urna_id1: integer (nullable = true)\n",
            " |-- urna_id2: integer (nullable = true)\n",
            " |-- tipo_urna1: string (nullable = true)\n",
            " |-- tipo_urna2: string (nullable = true)\n",
            " |-- data_geracao: string (nullable = true)\n",
            " |-- hora_geracao: string (nullable = true)\n",
            " |-- data_abertura: string (nullable = true)\n",
            " |-- data_encerramento: string (nullable = true)\n",
            " |-- aptos: integer (nullable = true)\n",
            " |-- comparecimento: integer (nullable = true)\n",
            " |-- abstencoes: integer (nullable = true)\n",
            " |-- data_carga_urna: string (nullable = true)\n",
            " |-- data_bu_recebido: string (nullable = true)\n",
            " |-- regiao: string (nullable = true)\n",
            " |-- nao_habilitados_biometria: integer (nullable = true)\n",
            " |-- secao_agregadas: string (nullable = true)\n",
            " |-- carga_1_urna: string (nullable = true)\n",
            " |-- carga_2_urna: string (nullable = true)\n",
            " |-- flashcard_urna: string (nullable = true)\n",
            " |-- data_emissao_bu: string (nullable = true)\n",
            " |-- junta_id: integer (nullable = true)\n",
            " |-- turma_id: integer (nullable = true)\n",
            " |-- urna: string (nullable = true)\n",
            " |-- data_bu: timestamp (nullable = true)\n",
            " |-- T_FIMBU_MIN: integer (nullable = true)\n",
            " |-- T_VOTO_SEG: integer (nullable = true)\n",
            " |-- T_FXVOTO: string (nullable = true)\n",
            " |-- T_FXFIMBU: string (nullable = true)\n",
            " |-- T_BU_5MIN: integer (nullable = true)\n",
            " |-- LOG_MODELO: integer (nullable = true)\n",
            " |-- LOG_AUDITAVEL: integer (nullable = true)\n",
            " |-- LOG_FG2020: string (nullable = true)\n",
            " |-- LOG_FGSOLICITA: integer (nullable = true)\n",
            " |-- LOG_NOMEARQLOG: string (nullable = true)\n",
            " |-- P_ESQ: integer (nullable = true)\n",
            " |-- P_DIR: integer (nullable = true)\n",
            " |-- P_INV: integer (nullable = true)\n",
            " |-- P_VAL: integer (nullable = true)\n",
            " |-- P_TOT: integer (nullable = true)\n",
            " |-- P_MITOVAL: float (nullable = true)\n",
            " |-- G_ESQ: integer (nullable = true)\n",
            " |-- G_DIR: integer (nullable = true)\n",
            " |-- G_INV: integer (nullable = true)\n",
            " |-- G_VAL: integer (nullable = true)\n",
            " |-- G_TOT: integer (nullable = true)\n",
            " |-- G_DIRVAL: float (nullable = true)\n",
            " |-- S_ESQ: integer (nullable = true)\n",
            " |-- S_DIR: integer (nullable = true)\n",
            " |-- S_INV: integer (nullable = true)\n",
            " |-- S_VAL: integer (nullable = true)\n",
            " |-- S_TOT: integer (nullable = true)\n",
            " |-- S_DIRVAL: float (nullable = true)\n",
            " |-- PG_DIR: integer (nullable = true)\n",
            " |-- PS_DIR: integer (nullable = true)\n",
            " |-- FG_BOLSO0: integer (nullable = true)\n",
            " |-- FG_LULA0: integer (nullable = true)\n",
            " |-- RAZAO_BOLSO_LULA: float (nullable = true)\n",
            " |-- RAZAO_LULA_BOLSO: float (nullable = true)\n",
            " |-- FG_2X_BOLSO_LULA: integer (nullable = true)\n",
            " |-- FG_2X_LULA_BOLSO: integer (nullable = true)\n",
            " |-- FG_4X_BOLSO_LULA: integer (nullable = true)\n",
            " |-- FG_4X_LULA_BOLSO: integer (nullable = true)\n",
            " |-- DIF_LULA_BOLSO: integer (nullable = true)\n",
            " |-- DIF_BOLSO_LULA: integer (nullable = true)\n",
            " |-- correspondencia_esperada: integer (nullable = true)\n",
            " |-- origem_voto: string (nullable = true)\n",
            " |-- divergencia: string (nullable = true)\n",
            " |-- uflat: double (nullable = true)\n",
            " |-- uflon: double (nullable = true)\n",
            " |-- clat: double (nullable = true)\n",
            " |-- clon: double (nullable = true)\n",
            " |-- city_no_accents: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sql = \"SELECT regiao, cidade, count(*) as qty_urnas, sum(abstencoes)/sum(aptos) * 100 as perc_abst FROM vc GROUP BY 1, 2 HAVING count(*) > 100 order by perc_abst desc\"\n",
        "\n",
        "sql = '''\n",
        "  SELECT \n",
        "    cidade, \n",
        "    MAX(A.uf) as uf, \n",
        "    MAX(B.pop_21) as pop, \n",
        "    SUM(A.aptos) as aptos,\n",
        "    ((SUM(A.aptos)/MAX(B.pop_21)) -1) * 100 as error,\n",
        "    CASE WHEN sum(bolsonaro) > sum(lula) THEN 'BOLSONARO' \n",
        "      ELSE 'LULA' END as winner \n",
        "  FROM vc A \n",
        "    JOIN municipios B ON lower(A.city_no_accents)=lower(B.no_accents) and lower(A.uf)=lower(B.uf_code) \n",
        "    GROUP BY cidade HAVING SUM(A.aptos)>(MAX(B.pop_21))'''\n",
        "city_with_issues = spark.sql(sql)\n",
        "city_with_issues.createOrReplaceTempView(\"city_issues\")\n",
        "\n",
        "sql = '''\n",
        "    select cidade, uf, round(error, 1) as error, aptos, pop, winner from city_issues order by error desc\n",
        "'''\n",
        "pdf = spark.sql(sql).toPandas()\n",
        "pdf.to_csv(path + \"/MyDrive/city_with_issues.csv\")\n",
        "\n"
      ],
      "metadata": {
        "id": "mpD2uxyMsCEf"
      },
      "execution_count": 91,
      "outputs": []
    }
  ]
}